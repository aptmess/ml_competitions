{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FINAL SUBMISSION TASK3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2JQuEQqEQ5m0"},"source":["# TASK3 - –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –®–∏—Ä–æ–∫–æ–≤"]},{"cell_type":"markdown","metadata":{"id":"JSG4Ngd5Q92E"},"source":["## Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KDwqlJw0cn7","executionInfo":{"status":"ok","timestamp":1629004634062,"user_tz":-180,"elapsed":239044,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"256d6b70-7c01-45da-a9d6-5ba6b640b087"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tJ1-Y6YGPo-o"},"source":["–ü–µ—Ä–µ–π–¥–µ–º –≤ —Ä–∞–±–æ—á–∏–π –∫–∞—Ç–∞–ª–æ–≥ —Å–æ—Ä–µ–Ω–æ–≤–∞–Ω–∏—è"]},{"cell_type":"code","metadata":{"id":"K5m4OpF7PEbo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629004636233,"user_tz":-180,"elapsed":329,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"8d350212-f381-488c-ee8d-286fdaf3d775"},"source":["cd /content/drive/MyDrive/digital_breakthrough/task_3"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/digital_breakthrough/task_3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7nVCVkAQPrVN"},"source":["–£—Å—Ç–∞–Ω–æ–≤–∏–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–º —Å—Ä–µ–¥—É."]},{"cell_type":"code","metadata":{"id":"g57naKGtkvGZ"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw3aYUOT0XKH","executionInfo":{"status":"ok","timestamp":1629004664509,"user_tz":-180,"elapsed":456,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"eca5adaf-4337-4657-8de4-1fd3f0b0c4a5"},"source":["cd /content/drive/MyDrive/digital_breakthrough/task_3"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/digital_breakthrough/task_3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZbjslPrQPvEl"},"source":["## Loading Additional Data\n","\n","### –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"]},{"cell_type":"markdown","metadata":{"id":"23bKMRbEPyWX"},"source":["–î–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é API –Ω–∞ —Å–∞–π—Ç–µ [–æ—Ç–∫—Ä—ã—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö](https://opendata.mkrf.ru/item/api) –±—ã–ª–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ 100 —Ç—ã—Å—è—á —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –≤ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ [–Ω–æ—É—Ç–±—É–∫–µ](https://drive.google.com/file/d/1DUz4zTwo6jGutC-peDL8Zs5Y9PqyhMdl/view?usp=sharing)  (`,./notebooks/loaders/02. LoaderJson.ipynb`) —Ñ—É–Ω–∫—Ü–∏—è–º–∏ `generate_api` –∏ `get_data`, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ã–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é `./data/load_<typology_name>`, –∞ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ –æ–¥–Ω—É –æ–±—â—É—é —Ç–∞–±–ª–∏—Ü—É `train_full_load.csv`. "]},{"cell_type":"markdown","metadata":{"id":"fRBKxiWwRkRI"},"source":["###  –î–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–æ–∫\n","\n","–î–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —è —Å–∫–∞—á–∞–ª —Ñ–æ—Ç–∫–∏ –∏–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ `train_url_only.csv` –≤ –ø–∞–ø–∫—É `./data/downloaded_images/`."]},{"cell_type":"markdown","metadata":{"id":"3ompQmjQ0dth"},"source":["## Training (Optional)\n","\n","### –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n","\n","–î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª:\n","\n","- Tokenizer –Ω–∞ 111000 —Å–ª–æ–≤, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ `WhiteSpace` –∏ `Digits`\n","- –û–±—É—á–∏–ª —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ 8 —ç–ø–æ—Ö–∞—Ö–∞ –Ω–∞ –ø–æ–ª–Ω—ã—Ö —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø–æ–¥—Ä–æ–±–Ω–µ–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–æ–∂–Ω–æ –∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è –≤ —Ñ–∞–π–ª–µ `./src/configs/main_exp_v1.yaml`\n","- –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–∏–ª –º–æ–¥–µ–ª—å `DistillBert`, –æ–±—É—á–∞—è –Ω–∞ 5 —ç–ø–æ—Ö–∞—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é `distilbert`. Tokenizer –±—ã–ª –ø–æ–ª—É—á–µ–Ω –Ω–∞ 70 –∫ —Å–ª–æ–≤ - –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å –≤ —Ñ–∞–π–ª–µ `./src/configs/main_config.yaml`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-GH7Ct9R5cR","executionInfo":{"status":"ok","timestamp":1629005272533,"user_tz":-180,"elapsed":14688,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"7af76ed4-7084-404b-8338-05bde5045178"},"source":["import logging\n","from src.predict import prediction\n","from airotica.airotica import detectron\n","from src.train import train_description_model\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","log = logging.getLogger(__name__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["{\"asctime\": \"2021-08-15 05:27:51\", \"name\": \"matplotlib.pyplot\", \"filename\": \"pyplot.py\", \"levelname\": \"DEBUG\", \"message\": \"Loaded backend module://ipykernel.pylab.backend_inline version unknown.\"}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"twc_HSkgSbRH"},"source":["–û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏–ª–æ—Å—å –¥–∞–Ω–Ω–æ–π –∫–æ–º–∞–Ω–¥–Ω–æ–π."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8YCS5jLcSCTh","executionInfo":{"status":"ok","timestamp":1628092653802,"user_tz":-180,"elapsed":4793853,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"23f04047-6c39-418e-ab64-271bbeda4ebb"},"source":["train_description_model(config_name='main_exp_v1.yaml')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Savedir: /content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4\n","0                                               –≥—Ä–∞—Ñ–∏–∫–∞\n","1                                             –¥–æ–∫—É–º–µ–Ω—Ç—ã\n","2                                              –∂–∏–≤–æ–ø–∏—Å—å\n","3                                                –æ—Ä—É–∂–∏–µ\n","4                                   –ø—Ä–µ–¥–º–µ—Ç—ã –∞—Ä—Ö–µ–æ–ª–æ–≥–∏–∏\n","5                 –ø—Ä–µ–¥–º–µ—Ç—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–Ω–∞—É—á–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n","6                   –ø—Ä–µ–¥–º–µ—Ç—ã –º–∏–Ω–µ—Ä–∞–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n","7                                  –ø—Ä–µ–¥–º–µ—Ç—ã –Ω—É–º–∏–∑–º–∞—Ç–∏–∫–∏\n","8                           –ø—Ä–µ–¥–º–µ—Ç—ã –ø–µ—á–∞—Ç–Ω–æ–π –ø—Ä–æ–¥—É–∫—Ü–∏–∏\n","9     –ø—Ä–µ–¥–º–µ—Ç—ã –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–≥–æ –∏—Å–∫—É—Å—Å—Ç–≤–∞, –±—ã—Ç–∞ –∏ —ç—Ç–Ω–æ–≥—Ä–∞—Ñ–∏–∏\n","10                                     –ø—Ä–µ–¥–º–µ—Ç—ã —Ç–µ—Ö–Ω–∏–∫–∏\n","11                                         —Ä–µ–¥–∫–∏–µ –∫–Ω–∏–≥–∏\n","12                                           —Å–∫—É–ª—å–ø—Ç—É—Ä–∞\n","13                                —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∏ –Ω–µ–≥–∞—Ç–∏–≤—ã\n","Name: category, dtype: object\n","/content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4/item_name.txt /content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4/item_name_train.txt /content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4/item_name_valid.txt /content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4/train_data.csv 14\n"],"name":"stdout"},{"output_type":"stream","text":["using `logging_steps` to initialize `eval_steps` to 500\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n","Creating features from dataset file at /content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4/item_name_train.txt\n","Creating features from dataset file at /content/drive/MyDrive/digital_breakthrough/task_3/data/description/v4/item_name_valid.txt\n","***** Running training *****\n","  Num examples = 147319\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 23020\n"],"name":"stderr"},{"output_type":"stream","text":["<transformers.data.datasets.language_modeling.LineByLineTextDataset object at 0x7f72c33b1210>\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='16326' max='23020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [16326/23020 1:27:08 < 35:44, 3.12 it/s, Epoch 3.55/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>8.313100</td>\n","      <td>7.916295</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>7.845800</td>\n","      <td>7.702612</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>7.639700</td>\n","      <td>7.642996</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>7.512000</td>\n","      <td>7.499543</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>7.383200</td>\n","      <td>7.377310</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>7.246600</td>\n","      <td>7.264523</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>7.107100</td>\n","      <td>7.073224</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>7.001700</td>\n","      <td>6.913572</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>6.875100</td>\n","      <td>6.713515</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>6.704000</td>\n","      <td>6.724208</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>6.601700</td>\n","      <td>6.623839</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>6.589900</td>\n","      <td>6.480356</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>6.440400</td>\n","      <td>6.408947</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>6.317200</td>\n","      <td>6.334692</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>6.215600</td>\n","      <td>6.309314</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>6.240400</td>\n","      <td>6.192551</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>6.175300</td>\n","      <td>6.138880</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>6.109300</td>\n","      <td>6.114434</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>5.999200</td>\n","      <td>6.050646</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>5.942900</td>\n","      <td>5.947344</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>5.891400</td>\n","      <td>5.922942</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>5.809800</td>\n","      <td>5.858764</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>5.874800</td>\n","      <td>5.856677</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>5.725000</td>\n","      <td>5.697091</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>5.748900</td>\n","      <td>5.705881</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>5.691100</td>\n","      <td>5.734134</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>5.617500</td>\n","      <td>5.678579</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>5.623400</td>\n","      <td>5.607348</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>5.555700</td>\n","      <td>5.624840</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>5.584100</td>\n","      <td>5.637661</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>5.474600</td>\n","      <td>5.607300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>5.479700</td>\n","      <td>5.586270</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='23020' max='23020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [23020/23020 2:03:30, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>8.313100</td>\n","      <td>7.916295</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>7.845800</td>\n","      <td>7.702612</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>7.639700</td>\n","      <td>7.642996</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>7.512000</td>\n","      <td>7.499543</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>7.383200</td>\n","      <td>7.377310</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>7.246600</td>\n","      <td>7.264523</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>7.107100</td>\n","      <td>7.073224</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>7.001700</td>\n","      <td>6.913572</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>6.875100</td>\n","      <td>6.713515</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>6.704000</td>\n","      <td>6.724208</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>6.601700</td>\n","      <td>6.623839</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>6.589900</td>\n","      <td>6.480356</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>6.440400</td>\n","      <td>6.408947</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>6.317200</td>\n","      <td>6.334692</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>6.215600</td>\n","      <td>6.309314</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>6.240400</td>\n","      <td>6.192551</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>6.175300</td>\n","      <td>6.138880</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>6.109300</td>\n","      <td>6.114434</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>5.999200</td>\n","      <td>6.050646</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>5.942900</td>\n","      <td>5.947344</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>5.891400</td>\n","      <td>5.922942</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>5.809800</td>\n","      <td>5.858764</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>5.874800</td>\n","      <td>5.856677</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>5.725000</td>\n","      <td>5.697091</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>5.748900</td>\n","      <td>5.705881</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>5.691100</td>\n","      <td>5.734134</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>5.617500</td>\n","      <td>5.678579</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>5.623400</td>\n","      <td>5.607348</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>5.555700</td>\n","      <td>5.624840</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>5.584100</td>\n","      <td>5.637661</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>5.474600</td>\n","      <td>5.607300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>5.479700</td>\n","      <td>5.586270</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>5.477300</td>\n","      <td>5.548668</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>5.433000</td>\n","      <td>5.492341</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>5.403600</td>\n","      <td>5.440227</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>5.406800</td>\n","      <td>5.380825</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>5.359700</td>\n","      <td>5.390903</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>5.286600</td>\n","      <td>5.421735</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>5.320000</td>\n","      <td>5.364042</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>5.242800</td>\n","      <td>5.320073</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>5.301000</td>\n","      <td>5.390306</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>5.272900</td>\n","      <td>5.382905</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>5.243900</td>\n","      <td>5.349640</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>5.221100</td>\n","      <td>5.294583</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>5.248600</td>\n","      <td>5.198127</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>5.241700</td>\n","      <td>5.267162</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 6138\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to /content/drive/MyDrive/digital_breakthrough/task_3/models/lm_models/roberta_wordpiece_100k/final\n","Configuration saved in /content/drive/MyDrive/digital_breakthrough/task_3/models/lm_models/roberta_wordpiece_100k/final/config.json\n","Model weights saved in /content/drive/MyDrive/digital_breakthrough/task_3/models/lm_models/roberta_wordpiece_100k/final/pytorch_model.bin\n","tokenizing:   0%|          | 0/149798 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149798/149798 [00:36<00:00, 4085.25it/s]\n","loading configuration file /content/drive/MyDrive/digital_breakthrough/task_3/models/lm_models/roberta_wordpiece_100k/final/config.json\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"dim\": 512,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dim\": 2048,\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"roberta\",\n","  \"n_heads\": 8,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n","loading weights file /content/drive/MyDrive/digital_breakthrough/task_3/models/lm_models/roberta_wordpiece_100k/final/pytorch_model.bin\n","Loading PyTorch weights from /content/drive/MyDrive/digital_breakthrough/task_3/models/lm_models/roberta_wordpiece_100k/final/pytorch_model.bin\n","PyTorch checkpoint contains 165,699,488 parameters\n","Loaded 165,003,264 parameters in the TF 2.0 model.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 32)]         0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 32)]         0                                            \n","__________________________________________________________________________________________________\n","roberta (TFRobertaMainLayer)    TFBaseModelOutputWit 165593856   input_3[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           roberta[0][13]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 14)           10766       global_average_pooling1d_1[0][0] \n","==================================================================================================\n","Total params: 165,604,622\n","Trainable params: 165,604,622\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/5\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["1639/1639 [==============================] - 521s 307ms/step - loss: 0.7234 - f1_score: nan - val_loss: 0.6281 - val_f1_score: 0.7940\n","Epoch 2/5\n","1639/1639 [==============================] - 500s 305ms/step - loss: 0.5320 - f1_score: 0.8239 - val_loss: 0.5968 - val_f1_score: 0.8078\n","Epoch 3/5\n","1639/1639 [==============================] - 500s 305ms/step - loss: 0.4371 - f1_score: 0.8565 - val_loss: 0.5793 - val_f1_score: 0.8172\n","Epoch 4/5\n","1639/1639 [==============================] - 500s 305ms/step - loss: 0.3555 - f1_score: 0.8826 - val_loss: 0.6061 - val_f1_score: 0.8153\n","Epoch 5/5\n","1639/1639 [==============================] - 500s 305ms/step - loss: 0.2839 - f1_score: 0.9066 - val_loss: 0.6464 - val_f1_score: 0.8143\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses, pooler_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/digital_breakthrough/task_3/models/model/roberta_wordpiece_100k/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/digital_breakthrough/task_3/models/model/roberta_wordpiece_100k/assets\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"H0ul10tHTJVo"},"source":["–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª–µ–∂–∞—Ç –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `./models`, –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã –≤—ã—à–µ, –±—ã–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –≤–µ—Å–∞:\n","\n","- [Tokenizer](https://drive.google.com/file/d/1-miSGxcO2QKlFRacVX9B99QJnsOAJrjg/view?usp=sharing)\n","- [Language Model](https://drive.google.com/drive/folders/1-oZyq102MxveAUL1Xdhqan_mzob7e8db?usp=sharing)\n","- [Classification Model](https://drive.google.com/drive/folders/1JPHvhjvvHgag_cYbb0YUw3kG81oJGbeS?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"Cxod8wfqTEID"},"source":["### Image Data\n","\n","–ë—ã–ª –æ–±—É—á–µ–Ω –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤ [–Ω–æ—É—Ç–±—É–∫–µ full_train.ipynb](https://drive.google.com/file/d/13mzBLbb1HXdh893rT9JNakNhPrv-7URP/view?usp=sharing) –Ω–∞ 14 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –∏–∑ —Ñ–∞–π–ª–∞ `train_url_only.csv`, –∏—Å–∫–ª—é—á–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—é `–ø—Ä–æ—á–µ–µ` –Ω–∞ 20 —ç–ø–æ—Ö–∞—Ö —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ `resnext-152-8d`, —Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–µ—Å–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ [–∑–¥–µ—Å—å](https://drive.google.com/file/d/1-1bxo2Niwy_j7eaPv6SaaR34lVsJkRvt/view?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"Ewwvm1LzVYoK"},"source":["### Code\n","\n","–í–µ—Å—å –∫–æ–¥ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ª–µ–∂–∏—Ç –≤ –ø–∞–ø–∫–µ `./src/`, –∞ –¥–ª—è `image data` - `./airotica`. –î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å `yaml` –º–∞–Ω–∏—Ñ–µ—Å—Ç."]},{"cell_type":"markdown","metadata":{"id":"EyBwlSHghvEJ"},"source":["## Predict\n","\n","–ó–∞–¥–∞—á—É —è —Ä–∞–∑–±–∏–ª –Ω–∞ –¥–≤–µ —á–∞—Å—Ç–∏\n","\n","1. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ `description`\n","2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ `images`\n","3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –æ–±–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞\n","\n","–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∏–º–µ—é—â–∏—Ö –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–ª–∞–ª–æ—Å—å —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é."]},{"cell_type":"markdown","metadata":{"id":"k4p7BnDxjXd_"},"source":["–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è `description`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYeWI0quMfSF","executionInfo":{"status":"ok","timestamp":1629008608857,"user_tz":-180,"elapsed":17954,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"1ecfbdc0-353b-4e4c-fbbf-35c65b28526f"},"source":["pred_desc = prediction(config_name=\"predict_full.yaml\")"],"execution_count":40,"outputs":[{"output_type":"stream","text":["tokenizing:   0%|          | 0/676 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 676/676 [00:00<00:00, 8776.30it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["3/3 [==============================] - 2s 53ms/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lac2S9TnjbKh"},"source":["–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDmAPcukIaUw","executionInfo":{"status":"ok","timestamp":1629006543359,"user_tz":-180,"elapsed":278218,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}},"outputId":"f203c145-0f77-4946-e4ed-95377eaf95ee"},"source":["images_prediction_2 = detectron(config_name='config5.yml', \n","                                save_path='./sub/_pred_new.csv',\n","                                model_path='./EXPERIMENTS/full_res/model_0001_0.857586.pth',\n","                                model_type='resnext101_32x8d',\n","                                save_result=False,\n","                                return_result=True,\n","                                use_description=True\n","                              )"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1223/1223 [04:35<00:00,  4.44it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L0SX9NS3UfSS","executionInfo":{"status":"ok","timestamp":1629007648974,"user_tz":-180,"elapsed":1682,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}}},"source":["import pandas as pd\n","\n","from definitions import DATA_PATH, SUB_PATH\n","\n","train = pd.read_csv(DATA_PATH / 'train.csv')\n","my = pd.read_csv('./sub/imnlp.csv')\n","\n","sample_submission = pd.read_csv(DATA_PATH / 'sample_submission.csv')\n","\n","train_labels = train.typology.unique()\n","typology_to_label = dict(\n","    zip(\n","        sorted(train_labels),\n","        range(\n","            len(train_labels)\n","        )\n","    )\n",")\n","\n","label_to_typology = {v: k for k, v in typology_to_label.items()}\n","\n","MAPPER = {0: 0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, \n","          7:7, 8:8, 9:9, 10:10, 11:12, 12:13, 13:14,\n","          -1: -1\n","          }\n","\n","tst = (\n","    images_prediction_2[images_prediction_2.sign_0 != -1]['sign_0']\n","    .map(MAPPER)\n","    .map(label_to_typology)\n",")\n","\n","sample_submission.loc[pred_desc.index, 'typology'] = pred_desc.values\n","sample_submission.loc[tst.index, 'typology'] = tst.values\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tU1zThwwUrko"},"source":["–¢–∞–∫ –∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ª—É—á—à–µ–µ –ø–æ private —Ä–µ—à–µ–Ω–∏–µ."]},{"cell_type":"code","metadata":{"id":"VlLewL2WUlWp","executionInfo":{"status":"ok","timestamp":1629007674143,"user_tz":-180,"elapsed":650,"user":{"displayName":"Aleksandr Shirokov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsVAQHPkRgO2wPgkH9jP3xC6JRooI58PuUGJHd=s64","userId":"08072078113294094856"}}},"source":["sample_submission.to_csv(SUB_PATH / 'BEST_PRIVATE' /'imnlp.csv', index=False)"],"execution_count":16,"outputs":[]}]}